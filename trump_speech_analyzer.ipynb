{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import datefinder\n",
    "import spacy\n",
    "import pandas as pd\n",
    "from gensim import corpora, models, similarities\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stops = set([s for s in STOPWORDS])\n",
    "\n",
    "# adding corpus-specific stopwords to gensim's default stopwords:\n",
    "customstops = set(['applause','booing','inaudible','cheers','laughter'])\n",
    "stops = stops.union(customstops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    return [token for token in simple_preprocess(text) if token not in stops]\n",
    "\n",
    "def get_speech(doc):\n",
    "    length = 0\n",
    "    segs = doc.split(\"\\n\\n\\n\")\n",
    "    for i in segs:\n",
    "        if len(i) > length:\n",
    "            length = len(i)\n",
    "    speech=[i for i in segs if len(i)==length]\n",
    "    return speech[0]\n",
    "\n",
    "def get_date(d):\n",
    "    matches = list(datefinder.find_dates(d))\n",
    "    if len(matches)>0:\n",
    "        return matches[0]\n",
    "    else:\n",
    "        return \"no date found\"\n",
    "    \n",
    "def get_ne_list(doc):\n",
    "    return [e.text for e in list(nlp(doc).ents)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "html = requests.get(\"http://www.presidency.ucsb.edu/2016_election_speeches.php?candidate=45&campaign=2016TRUMP&doctype=5000\")\n",
    "\n",
    "soup = BeautifulSoup(html.text, 'html.parser')\n",
    "\n",
    "links = []\n",
    "for a in soup.find_all('a'):\n",
    "    if a['href'].startswith(\"../ws/index.php?pid=\"):\n",
    "        links.append(a['href'])\n",
    "\n",
    "links = [l.replace(\"../ws/index.php?\",\"http://www.presidency.ucsb.edu/ws/?\") for l in links]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "speeches = []\n",
    "citations = []\n",
    "\n",
    "for l in links:\n",
    "    doc = requests.get(l)\n",
    "    docsoup = BeautifulSoup(doc.text, 'html.parser')\n",
    "    speech = get_speech(docsoup.get_text())\n",
    "    speeches.append(speech.split(\"\\nCitation:\")[0])\n",
    "    citations.append(speech.split(\"\\nCitation:\")[1])\n",
    "    \n",
    "dates = [get_date(c) for c in citations]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sentiment = [TextBlob(s).sentiment.polarity for s in speeches]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(sentiment).idxmin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Highest Sentiment Speech:\n",
      " Donald J. Trump: \"Remarks at Great Faith International Ministries in Detroit, Michigan,\" September 3, 2016. Online by Gerhard Peters and John T. Woolley, The American Presidency Project. http://www.presidency.ucsb.edu/ws/?pid=119199.\n",
      "\n",
      "======================================\n",
      "\n",
      "Lowest Sentiment Speech:\n",
      " Donald J. Trump: \"Remarks at the Jeffco Fairgrounds Event Center in Golden, Colorado,\" October 29, 2016. Online by Gerhard Peters and John T. Woolley, The American Presidency Project. http://www.presidency.ucsb.edu/ws/?pid=119181.\n"
     ]
    }
   ],
   "source": [
    "print(\"Highest Sentiment Speech:\")\n",
    "print(citations[pd.Series(sentiment).idxmax()])\n",
    "print('\\n======================================\\n')\n",
    "print(\"Lowest Sentiment Speech:\")\n",
    "print(citations[pd.Series(sentiment).idxmin()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "entities = []\n",
    "\n",
    "for s in speeches:\n",
    "    ents = nlp(s).ents\n",
    "    for e in ents:\n",
    "        entities.append((e.label_, e.text))\n",
    "\n",
    "s = pd.Series(entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "speeches_token_list = [tokenize(s) for s in speeches]\n",
    "# speeches_ne_list = [get_ne_list(s) for s in speeches]\n",
    "\n",
    "# dictionary = corpora.Dictionary(speeches_ne_list)\n",
    "dictionary = corpora.Dictionary(speeches_token_list)\n",
    "\n",
    "# corpus = [dictionary.doc2bow(s) for s in speeches_ne_list]\n",
    "corpus = [dictionary.doc2bow(s) for s in speeches_token_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# transform the corpus from bag-of-words to Tfidf:\n",
    "tfidf = models.TfidfModel(corpus)\n",
    "corpus_tfidf = tfidf[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        topic_0       topic_1       topic_2     topic_3      topic_4  \\\n",
      "0       indiana         cyber         maine    michigan           va   \n",
      "1         flint  philadelphia      michigan       haiti     veterans   \n",
      "2       jackson          navy      donating       gonna      defense   \n",
      "3         party  pennsylvania      question   venezuela      missile   \n",
      "4       african       arizona           tpp      legion        guard   \n",
      "5         black         gonna         flint   wikileaks    employers   \n",
      "6         looks        health         fight      castro  mississippi   \n",
      "7            ll      premiums      speeches     florida          war   \n",
      "8         water       college      virginia         dnc      bonuses   \n",
      "9      audience     brilliant  universities     student         duty   \n",
      "10          ubs      colorado         drink      mexico      savings   \n",
      "11       bishop      deported           ban       flint         navy   \n",
      "12       police     immigrant        opioid    clintons      veteran   \n",
      "13  traffickers           gas        follow    veterans       mental   \n",
      "14       follow       illegal      election       mills        folks   \n",
      "15         mike      question          girl       think       police   \n",
      "16     veterans      criminal      lobbying     african      african   \n",
      "17       mexico         loved          cars       folks       parent   \n",
      "18        pence        estate  announcement     detroit        cyber   \n",
      "19    treatment         shale     questions      bernie     accounts   \n",
      "20      percent       natural        reduce        know    solutions   \n",
      "21         said      smallest       lobbied      emails      student   \n",
      "22        drugs       methods       dreamed  democratic           ll   \n",
      "23     children          laws          jobs       cuban       number   \n",
      "24         jobs          mike    endowments          va      enforce   \n",
      "\n",
      "       topic_5       topic_6  \n",
      "0        farms        israel  \n",
      "1         iowa        reince  \n",
      "2     fighting          mike  \n",
      "3   corruption         folks  \n",
      "4      detroit         think  \n",
      "5        guard          said  \n",
      "6          tpp          know  \n",
      "7       policy            ok  \n",
      "8        legal          rudy  \n",
      "9     position      question  \n",
      "10       wages           lot  \n",
      "11     african            ll  \n",
      "12     machine  unbelievable  \n",
      "13    michigan          mean  \n",
      "14     equally        nevada  \n",
      "15    policies       believe  \n",
      "16     reforms      deadline  \n",
      "17    insiders            oh  \n",
      "18        grow       amnesty  \n",
      "19      future   palestinian  \n",
      "20        isis           got  \n",
      "21       islam   ndamendment  \n",
      "22       voice      register  \n",
      "23     society       october  \n",
      "24      attack         tough  \n"
     ]
    }
   ],
   "source": [
    "lda = models.LdaModel(corpus_tfidf, id2word=dictionary, num_topics=7)\n",
    "\n",
    "# using pandas to collect topics in nice tabular format\n",
    "topn=25\n",
    "index = range(topn)\n",
    "df = pd.DataFrame(index=index)\n",
    "for i in range(lda.num_topics):\n",
    "    t = [w[0] for w in lda.show_topic(i, topn=topn)]\n",
    "    df['topic_%s' % i] = pd.Series(t)\n",
    "\n",
    "print(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
